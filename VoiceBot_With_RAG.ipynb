{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "220db9c0-d6fc-44e0-acf4-8f11051cbc22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading exisiting vector database\n",
      "Sound to text time: 1.308748722076416\n",
      "Model response time: 0.9331905841827393\n",
      "./output_voices/speech.mp3\n",
      "Text to sound time: 1.5953500270843506\n",
      "==================================================\n",
      "USER:  السلام عليكم. كيف الحالة.\n",
      "Assistant: وعليكم السلام ورحمة الله وبركاته. الحالة جيدة، شكراً لطرح السؤال. كيف أستطيع مساعدتك؟\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.chains import RetrievalQA\n",
    "from faster_whisper import WhisperModel\n",
    "from gtts import gTTS\n",
    "from groq import Groq\n",
    "from playsound import playsound \n",
    "\n",
    "class RAGVoiceBot:\n",
    "    def __init__(self, vector_db_path, knowldge_path, groq_token_path, whisper_size='base', model_name='llama-3.1-70b-versatile'):\n",
    "\n",
    "        self.load_groq_token(groq_token_path)\n",
    "        \n",
    "        self.embedding_model = HuggingFaceEmbeddings(model_name='sentence-transformers/paraphrase-MiniLM-L12-v2')\n",
    "        self.whisper_model = self.initialize_STT_model(whisper_size)\n",
    "        self.llm = self.initialize_llm(model_name)\n",
    "        self.qa_pipeline = self.initialize_qa_pipeline(vector_db_path, knowldge_path)\n",
    "\n",
    "    \n",
    "    def load_groq_token(self, groq_token_path):\n",
    "        with open(groq_token_path, 'r') as f:\n",
    "            os.environ[\"GROQ_API_KEY\"] = f.readline().strip()\n",
    "\n",
    "    def initialize_STT_model(self, whisper_size):\n",
    "        num_cores = os.cpu_count() // 2\n",
    "        return WhisperModel(\n",
    "            whisper_size,\n",
    "            device=\"cpu\",\n",
    "            compute_type=\"int8\",\n",
    "            cpu_threads=num_cores\n",
    "        )\n",
    "\n",
    "    def initialize_llm(self, model_name):\n",
    "        return ChatGroq(\n",
    "            model=model_name\n",
    "        )\n",
    "\n",
    "    def initialize_qa_pipeline(self, vector_db_path, knowldge_path):\n",
    "        if os.path.exists(vector_db_path):\n",
    "            print('Loading exisiting vector database')\n",
    "            vec_db = FAISS.load_local(vector_db_path, self.embedding_model, allow_dangerous_deserialization=True)\n",
    "        else:\n",
    "            print('Creating new vector database')\n",
    "            vec_db = self.create_vector_database_docs(knowldge_path)\n",
    "            vec_db.save_local(vector_db_path)\n",
    "\n",
    "\n",
    "        # The RAG pipeline\n",
    "        return RetrievalQA.from_chain_type(\n",
    "            llm=self.llm,\n",
    "            chain_type='stuff',\n",
    "            retriever=vec_db.as_retriever(),\n",
    "            return_source_documents=True\n",
    "        )\n",
    "\n",
    "    def create_vector_database_docs(self, knowldge_path):\n",
    "        loader = PyPDFLoader(knowldge_path)\n",
    "        documents = loader.load()\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=50)\n",
    "        docs = text_splitter.split_documents(documents)\n",
    "        return FAISS.from_documents(docs, self.embedding_model)\n",
    "        \n",
    "\n",
    "    def speach_to_text(self, audio_path):\n",
    "        segments, _ = self.whisper_model.transcribe(audio_path)\n",
    "        return ''.join(segment.text for segment in segments)\n",
    "\n",
    "    def generate_response(self, prompt):\n",
    "        return self.qa_pipeline.invoke(prompt)['result']\n",
    "\n",
    "    def text_to_speech(self, text, output_path='./output_voices/speech.mp3'):\n",
    "        print(output_path)\n",
    "        start = time.time()\n",
    "        tts = gTTS(text, lang='ar')\n",
    "        tts.save(output_path)\n",
    "        print(f'Text to sound time: {time.time() - start}')\n",
    "\n",
    "        # output_path = os.path.join(os.getcwd(), output_path)\n",
    "        \n",
    "        music = pyglet.media.load(output_path, streaming=False)\n",
    "        music.play()\n",
    "        os.remove(output_path)\n",
    "                \n",
    "    def process_audio_file(self, audio_path):\n",
    "        start = time.time()\n",
    "        transcription = self.speach_to_text(audio_path)\n",
    "        print(f'Sound to text time: {time.time() - start}')\n",
    "\n",
    "        start = time.time()\n",
    "        response = self.generate_response(transcription)\n",
    "        print(f'Model response time: {time.time() - start}')\n",
    "        \n",
    "        \n",
    "        self.text_to_speech(response)\n",
    "\n",
    "        return transcription, response\n",
    "\n",
    "audio_path = r\"C:\\Users\\zmlka\\Documents\\Sound Recordings\\Recording (3).m4a\"\n",
    "\n",
    "voice_bot = RAGVoiceBot(\n",
    "    knowldge_path='./knowledge_base/Mohamed Hassan.pdf',\n",
    "    groq_token_path='groq_token.txt',\n",
    "    vector_db_path='vector_db'\n",
    ")\n",
    "\n",
    "transcription, response = voice_bot.process_audio_file(audio_path)\n",
    "\n",
    "print('='*50)\n",
    "\n",
    "print(\"USER:\", transcription)\n",
    "print(\"Assistant:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596de5b1-2c34-4d71-ab6a-7e57876abb55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
